{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping World's Top Automobile Companies by Market Value using Python\n",
    "\n",
    "![](https://i.imgur.com/uCfkM0b.jpg)\n",
    "\n",
    "**Data** is the collection of facts!\n",
    "\n",
    "_**Web Scraping**_ is a technique used to automatically extract large amounts of data from websites and save it to a file or database. The data scraped will usually be in tabular or spreadsheet format(e.g : CSV file)\n",
    "\n",
    "\n",
    "Here, in this web scrapping we will scrap data from [value.today](https://www.value.today/world-top-companies/automobile).\n",
    "\n",
    "We'll use the Python libraries `requests` and `beautifulsoup4` to perform scrapping from the webpage.\n",
    "\n",
    "\n",
    "\n",
    "Here's an outline of the steps we'll follow:\n",
    "\n",
    "1. Download the webpage using `requests`\n",
    "2. Parse the HTML source code using `beautifulsoup4`\n",
    "3. Extract Company name ,Headquarters country,CEO ,Market Cap (in billion USD),Annual revenue(in million USD),Number of employees,Company website\n",
    "4. Compile the extracted information into and Python lists and dictionaries\n",
    "5. Extract and combine data from multiple pages\n",
    "6. Save the extracted information to a CSV file.\n",
    "\n",
    "\n",
    "By the end of the project, we'll create a CSV file in the following format:\n",
    "![](https://i.imgur.com/y8VVs41.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the webpage using `requests`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the `requests` library to download the web page.\n",
    "\n",
    "The library can be installed using `pip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library is now installed and imported.\n",
    "\n",
    "To download a page, we can use the `get` function from requests, which returns a response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "webpage = ' https://www.value.today/world-top-companies/automobile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(webpage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`requests.get` returns a response object containing the data from the web page and some other information.\n",
    "\n",
    "The `.status_code` property can be used to check if the response was successful. A successful response will have an [HTTP status code](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status) between 200 and 299."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The request was successful. We can get the contents of the page using `response.text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_contents = response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the number of characters of the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184047"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The page contains over 173254 characters!\n",
    "\n",
    "Here are the first 1000 characters of the page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html lang=\"en\" dir=\"ltr\" prefix=\"content: http://purl.org/rss/1.0/modules/content/  dc: http://purl.org/dc/terms/  foaf: http://xmlns.com/foaf/0.1/  og: http://ogp.me/ns#  rdfs: http://www.w3.org/2000/01/rdf-schema#  schema: http://schema.org/  sioc: http://rdfs.org/sioc/ns#  sioct: http://rdfs.org/sioc/types#  skos: http://www.w3.org/2004/02/skos/core#  xsd: http://www.w3.org/2001/XMLSchema# \">\\n  <head>\\n    <meta charset=\"utf-8\"/>\\n<script async src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2407955258669770\" crossorigin=\"anonymous\"></script>\\n<script>(adsbygoogle=window.adsbygoogle||[]).push({google_ad_client:\"ca-pub-2407955258669770\",enable_page_level_ads:true});</script><script>window.google_analytics_uacct=\"UA-121331115-1\";(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentN'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_contents[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell `page_content[:1000]` contains the [HTML](https://en.wikipedia.org/wiki/HTML) of the webpage [value.today](https://www.value.today/world-top-companies/automobile)\n",
    "\n",
    "We can also save it to a file and view the page locally within Jupyter using \"File > Open\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('webpage.html','w') as f:\n",
    "    f.write(page_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This page looks similar to the original page.\n",
    "\n",
    "![](https://i.imgur.com/rbWMVHS.png)\n",
    "\n",
    "In the section, we used the requests library to download a web page as HTML. We have successfully downloaded the webpage using `requests` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the HTML source code using `beautifulsoup4`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = BeautifulSoup(page_contents, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this `doc` object, we can navigate and search through the `HTML` for data that we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `doc` object contains several properties and methods for extracting information from the HTML document.\n",
    "\n",
    "[the documentation of BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tag = doc.find('title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `doc.find('title')` will give the title of the web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>World Top Automobile Companies by Market Value as on 2022</title>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To only get text out of the tag we use .text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'World Top Automobile Companies by Market Value as on 2022'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tag.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract company names, Headquarters country, CEOs, Market capitalization, Annual revenue, number of employees, company website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon inspecting the html code we get an idea that all the information that we need to scrape is under `li` tag with `class` attribute set to `row well clearfix`\n",
    "\n",
    "![](https://i.imgur.com/6OJ6rFN.png)\n",
    "\n",
    "Let's find all the `li` tags matching this class.\n",
    "\n",
    "We create a variable for value of Key-class as company_selector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_selector = \"row well clearfix\"\n",
    "company_tags = doc.find_all('li' , {'class' : company_selector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(company_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The web page contain 10 boxes of `li` tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Company Name\n",
    "\n",
    "![](https://i.imgur.com/jBswKpc.png)\n",
    "\n",
    "Now Let's create a `function` to extract all the `company names ` of first page using the `for loop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_of_companies(company_tags):\n",
    "    company_names = []\n",
    "    \n",
    "    for tag in company_tags:\n",
    "        c_name = tag.find('div' , {'class' : \"field field--name-node-title field--type-ds field--label-hidden field--item\"})\n",
    "        h2_tags = (c_name.find('h2' , {'class' : \"text-primary\"}))\n",
    "        company_names.append(h2_tags.find('a').text)\n",
    "    \n",
    "    return company_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call function `name_of_companies` to get the companies names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check the function\n",
    "name_of_companies(company_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headquarters Country\n",
    "\n",
    "![](https://i.imgur.com/MHJtL8L.png)\n",
    "\n",
    "Now Let's create a `function` to extract all the `headquarters` of first page using the `for loop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def headquarters_country(company_tags):\n",
    "    headquarter_country = []\n",
    "    \n",
    "    for tag in company_tags:\n",
    "        headquarters = tag.find('div' , {'class' : \"clearfix col-sm-12 field field--name-field-headquarters-of-company field--type-entity-reference field--label-above\"})\n",
    "        try:\n",
    "            hq = headquarters.find('div' , {'class' : \"field--item\"})\n",
    "            headquarter_country.append(hq.find('a').text)\n",
    "        except AttributeError:\n",
    "            headquarter_country.append(None)\n",
    "    return headquarter_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call function `headquarters_country` to get the headquarters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check the function\n",
    "headquarters_country(company_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEOs\n",
    "\n",
    "![](https://i.imgur.com/hJViahw.png)\n",
    "\n",
    "Now Let's create a `function` to extract all the `CEO names` of first page using the `for loop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_of_ceos(company_tags):\n",
    "    CEO_name = []\n",
    "    \n",
    "    for tag in company_tags:\n",
    "        ceo = tag.find('div' , {'class' : \"clearfix col-sm-12 field field--name-field-ceo field--type-entity-reference field--label-above\"})\n",
    "        try:\n",
    "            name = ceo.find('div' , {'class' : \"field--item\"})\n",
    "            CEO_name.append(name.find('a').text)\n",
    "        \n",
    "        except AttributeError:\n",
    "            CEO_name.append(None)\n",
    "        \n",
    "    return CEO_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call function `name_of_ceos` to get the CEOs names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's call the function\n",
    "name_of_ceos(company_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Market Capitalization\n",
    "\n",
    "![](https://i.imgur.com/4SmLn51.png)\n",
    "\n",
    "Now Let's create a `function` to extract all the `market cap` of first page using the `for loop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def market_capitalisation_in_billion_USdollars(company_tags):\n",
    "    market_capitalisation = []\n",
    "    \n",
    "    for tag in company_tags:\n",
    "        market_cap = tag.find('div' , {'class' : \"clearfix col-sm-6 field field--name-field-market-value-jan072022 field--type-float field--label-above\"})\n",
    "        try:\n",
    "            cap = market_cap.find('div' , {'class' : \"field--item\"}).text\n",
    "           \n",
    "            replace_USD = cap.replace(' Billion USD' , \"\").replace(',' , \"\")\n",
    "            \n",
    "            market_capitalisation.append(float(replace_USD))\n",
    "        \n",
    "        except AttributeError:\n",
    "            market_capitalisation.append(None)\n",
    "        \n",
    "    return market_capitalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call function `market_capitalisation_in_billion_USdollars` to get the market capitalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's call the function\n",
    "market_capitalisation_in_billion_USdollars(company_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual Revenue\n",
    "\n",
    "![](https://i.imgur.com/OnpKeBT.png)\n",
    "\n",
    "Now Let's create a `function` to extract all the `annual revenues` of first page using the `for loop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annual_revenue_in_million_USdollars(company_tags):\n",
    "    annual_revenue = []\n",
    "    \n",
    "    for tag in company_tags:\n",
    "        revenue = tag.find('div' , {'class' : \"clearfix col-sm-12 field field--name-field-revenue-in-usd field--type-float field--label-inline\"})\n",
    "        try:\n",
    "            annual = revenue.find('div' , {'class' : \"field--item\"}).text\n",
    "           \n",
    "            replace_USD = annual.replace(' Million USD' , \"\").replace(',' , \"\")\n",
    "            annual_revenue.append(float(replace_USD))\n",
    "        \n",
    "        except AttributeError:\n",
    "            annual_revenue.append(None)\n",
    "        \n",
    "    return annual_revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call function `annual_revenue_in_million_USdollars` to get the annual revenue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check the function\n",
    "annual_revenue_in_million_USdollars(company_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Employees\n",
    "\n",
    "![](https://i.imgur.com/xbbn1XI.png)\n",
    "\n",
    "Now Let's create a `function` to extract all the `number of employees` of first page using the `for loop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_employees(company_tags):\n",
    "    employees_count = []\n",
    "    \n",
    "    for tag in company_tags:\n",
    "        employees = tag.find('div' , {'class' : \"clearfix col-sm-12 field field--name-field-employee-count field--type-integer field--label-inline\"})\n",
    "        try:\n",
    "            count = employees.find('div' , {'class' : \"field--item\"}).text\n",
    "            n_replace = count.replace(',' , \"\")\n",
    "            employees_count.append(int(n_replace))\n",
    "        \n",
    "        except AttributeError:\n",
    "            employees_count.append(None)\n",
    "        \n",
    "    return employees_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call function `number_of_employees` to get the number of employees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let;s check the function\n",
    "number_of_employees(company_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Company Website\n",
    "\n",
    "![](https://i.imgur.com/tL3wze8.png)\n",
    "\n",
    "Now Let's create a `function` to extract all the `company website` of first page using the `for loop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def company_website(company_tags):\n",
    "    website = []\n",
    "    \n",
    "    for tag in company_tags:\n",
    "        c_url = tag.find('div' , {'class' : \"clearfix col-sm-12 field field--name-field-company-website field--type-link field--label-above\"})\n",
    "        try:\n",
    "            url = c_url.find('div' , {'class' : \"field--item\"})\n",
    "            website.append(url.find('a')['href'])\n",
    "        \n",
    "        except AttributeError:\n",
    "            website.append(None)\n",
    "        \n",
    "    return website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call function `company_website` to get the company website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check the function\n",
    "company_website(company_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have created `7` function. These are `name_of_companies`, `headquarters_country`, `name_of_ceos`, `market_capitalisation_in_billion_USdollars`, `annual_revenue_in_million_USdollars`, `number_of_employees`, `company_website`. And now we have developed an approach to extract the data from a block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the extracted information into and Python lists and dictionaries\n",
    "\n",
    "## Extract and combine data from multiple pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function to get any webpage and parse it using beautiful soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Unable to download page {}' .format(url))\n",
    "    page_contents = response.text\n",
    "    doc = BeautifulSoup(page_contents, 'html.parser')\n",
    "    \n",
    "    return doc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the function `get_page` to downlaod any web page and parse it using beautiful soup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a `dictionary` using all the functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/5cMet0o.png)\n",
    "\n",
    "As there are `90` pages on wesite, We will need to `loop` through all the pages. So that we can extract the data from all the pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page():\n",
    "    all_info_dict = {}\n",
    "   \n",
    "    all_info_dict = {\n",
    "        'companies_name':[],\n",
    "        'headquarters_country':[],\n",
    "        'CEOs_name':[],\n",
    "        'market_capitalisation_in_billion_USdollars':[],\n",
    "        'annual_revenue_in_million_USdollars':[],\n",
    "        'number_of_employees':[],\n",
    "        'company_website':[]\n",
    "            }\n",
    "    for page in range (0,90):\n",
    "\n",
    "        url = f\"https://www.value.today/world-top-companies/automobile?title=&field_headquarters_of_company_target_id&field_company_category_primary_target_id&field_company_website_uri=&field_market_value_jan072022_value=&page={page}\"\n",
    "        company_tags = get_page(url).find_all('li',class_='row well clearfix')\n",
    "\n",
    "        all_info_dict['companies_name'] += name_of_companies(company_tags)\n",
    "        all_info_dict['headquarters_country'] +=  headquarters_country(company_tags)\n",
    "        all_info_dict['CEOs_name'] += name_of_ceos(company_tags)\n",
    "        all_info_dict['market_capitalisation_in_billion_USdollars'] += market_capitalisation_in_billion_USdollars(company_tags)\n",
    "        all_info_dict['annual_revenue_in_million_USdollars'] += annual_revenue_in_million_USdollars(company_tags)\n",
    "        all_info_dict['number_of_employees'] += number_of_employees(company_tags)\n",
    "        all_info_dict['company_website'] += company_website(company_tags)\n",
    "        page = page + 1\n",
    "    return all_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas dataframe from dictionary\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_page_dataframe = pd.DataFrame(scrape_page())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>companies_name</th>\n",
       "      <th>headquarters_country</th>\n",
       "      <th>CEOs_name</th>\n",
       "      <th>market_capitalisation_in_billion_USdollars</th>\n",
       "      <th>annual_revenue_in_million_USdollars</th>\n",
       "      <th>number_of_employees</th>\n",
       "      <th>company_website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [companies_name, headquarters_country, CEOs_name, market_capitalisation_in_billion_USdollars, annual_revenue_in_million_USdollars, number_of_employees, company_website]\n",
       "Index: []"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's view the first 5 and last 5 rows\n",
    "scrape_page_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the extracted information to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_page_dataframe.to_csv('scrape_page_dataframe.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Here's what we've covered in this notebook\n",
    "\n",
    "1. Downloaded the webpage using `requests`\n",
    "2. Parsed the HTML source code using `beautifulsoup4`\n",
    "3. Extracted Company name, Headquarters country, CEO, Market Cap (in billion USD), Annual revenue(in million USD), Number of employees, Company website\n",
    "4. Compiled the extracted information into and Python lists and dictionaries\n",
    "5. Extracted and combine data from multiple pages\n",
    "6. Saved the extracted information to a CSV file.\n",
    "\n",
    "\n",
    "The CSV file we created has this format:\n",
    "\n",
    "![](https://i.imgur.com/Tvu88n0.png)\n",
    "\n",
    "Here's the complete code for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_of_companies(company_tags):\n",
    "    company_names = []\n",
    "    \n",
    "    for tag in company_tags:\n",
    "        c_name = tag.find('div' , {'class' : \"field field--name-node-title field--type-ds field--label-hidden field--item\"})\n",
    "        h2_tags = (c_name.find('h2' , {'class' : \"text-primary\"}))\n",
    "        company_names.append(h2_tags.find('a').text)\n",
    "    \n",
    "    return company_names\n",
    "\n",
    "\n",
    "def headquarters_country(company_tags):\n",
    "    headquarter_country = []\n",
    "    \n",
    "    for tag in company_tags:\n",
    "        headquarters = tag.find('div' , {'class' : \"clearfix col-sm-12 field field--name-field-headquarters-of-company field--type-entity-reference field--label-above\"})\n",
    "        try:\n",
    "            hq = headquarters.find('div' , {'class' : \"field--item\"})\n",
    "            headquarter_country.append(hq.find('a').text)\n",
    "        except AttributeError:\n",
    "            headquarter_country.append(None)\n",
    "    return headquarter_country\n",
    "\n",
    "\n",
    "def name_of_ceos(company_tags):\n",
    "    CEO_name = []\n",
    "    \n",
    "    for tag in company_tags:\n",
    "        ceo = tag.find('div' , {'class' : \"clearfix col-sm-12 field field--name-field-ceo field--type-entity-reference field--label-above\"})\n",
    "        try:\n",
    "            name = ceo.find('div' , {'class' : \"field--item\"})\n",
    "            CEO_name.append(name.find('a').text)\n",
    "        \n",
    "        except AttributeError:\n",
    "            CEO_name.append(None)\n",
    "        \n",
    "    return CEO_name\n",
    "\n",
    "\n",
    "def market_capitalisation_in_billion_USdollars(company_tags):\n",
    "    market_capitalisation = []\n",
    "    \n",
    "    for tag in company_tags:\n",
    "        market_cap = tag.find('div' , {'class' : \"clearfix col-sm-6 field field--name-field-market-value-jan072022 field--type-float field--label-above\"})\n",
    "        try:\n",
    "            cap = market_cap.find('div' , {'class' : \"field--item\"}).text\n",
    "           \n",
    "            replace_USD = cap.replace(' Billion USD' , \"\").replace(',' , \"\")\n",
    "            \n",
    "            market_capitalisation.append(float(replace_USD))\n",
    "        \n",
    "        except AttributeError:\n",
    "            market_capitalisation.append(None)\n",
    "        \n",
    "    return market_capitalisation\n",
    "\n",
    "\n",
    "def annual_revenue_in_million_USdollars(company_tags):\n",
    "    annual_revenue = []\n",
    "    \n",
    "    for tag in company_tags:\n",
    "        revenue = tag.find('div' , {'class' : \"clearfix col-sm-12 field field--name-field-revenue-in-usd field--type-float field--label-inline\"})\n",
    "        try:\n",
    "            annual = revenue.find('div' , {'class' : \"field--item\"}).text\n",
    "           \n",
    "            replace_USD = annual.replace(' Million USD' , \"\").replace(',' , \"\")\n",
    "            annual_revenue.append(float(replace_USD))\n",
    "        \n",
    "        except AttributeError:\n",
    "            annual_revenue.append(None)\n",
    "        \n",
    "    return annual_revenue\n",
    "\n",
    "\n",
    "def number_of_employees(company_tags):\n",
    "    employees_count = []\n",
    "    \n",
    "    for tag in company_tags:\n",
    "        employees = tag.find('div' , {'class' : \"clearfix col-sm-12 field field--name-field-employee-count field--type-integer field--label-inline\"})\n",
    "        try:\n",
    "            count = employees.find('div' , {'class' : \"field--item\"}).text\n",
    "            n_replace = count.replace(',' , \"\")\n",
    "            employees_count.append(int(n_replace))\n",
    "        \n",
    "        except AttributeError:\n",
    "            employees_count.append(None)\n",
    "        \n",
    "    return employees_count\n",
    "\n",
    "\n",
    "def company_website(company_tags):\n",
    "    website = []\n",
    "    \n",
    "    for tag in company_tags:\n",
    "        c_url = tag.find('div' , {'class' : \"clearfix col-sm-12 field field--name-field-company-website field--type-link field--label-above\"})\n",
    "        try:\n",
    "            url = c_url.find('div' , {'class' : \"field--item\"})\n",
    "            website.append(url.find('a')['href'])\n",
    "        \n",
    "        except AttributeError:\n",
    "            website.append(None)\n",
    "        \n",
    "    return website\n",
    "\n",
    "\n",
    "def get_page(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Unable to download page {}' .format(url))\n",
    "    page_contents = response.text\n",
    "    doc = BeautifulSoup(page_contents, 'html.parser')\n",
    "    \n",
    "    return doc\n",
    "\n",
    "\n",
    "def scrape_page():\n",
    "    all_info_dict = {}\n",
    "   \n",
    "    all_info_dict = {\n",
    "        'companies_name':[],\n",
    "        'headquarters_country':[],\n",
    "        'CEOs_name':[],\n",
    "        'market_capitalisation_in_billion_USdollars':[],\n",
    "        'annual_revenue_in_million_USdollars':[],\n",
    "        'number_of_employees':[],\n",
    "        'company_website':[]\n",
    "            }\n",
    "    for page in range (0,90):\n",
    "\n",
    "        url = f\"https://www.value.today/world-top-companies/automobile?title=&field_headquarters_of_company_target_id&field_company_category_primary_target_id&field_company_website_uri=&field_market_value_jan072022_value=&page={page}\"\n",
    "        company_tags = get_page(url).find_all('li',class_='row well clearfix')\n",
    "\n",
    "        all_info_dict['companies_name'] += name_of_companies(company_tags)\n",
    "        all_info_dict['headquarters_country'] +=  headquarters_country(company_tags)\n",
    "        all_info_dict['CEOs_name'] += name_of_ceos(company_tags)\n",
    "        all_info_dict['market_capitalisation_in_billion_USdollars'] += market_capitalisation_in_billion_USdollars(company_tags)\n",
    "        all_info_dict['annual_revenue_in_million_USdollars'] += annual_revenue_in_million_USdollars(company_tags)\n",
    "        all_info_dict['number_of_employees'] += number_of_employees(company_tags)\n",
    "        all_info_dict['company_website'] += company_website(company_tags)\n",
    "        page = page + 1\n",
    "    return all_info_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "\n",
    "* We can now fetch individual topic pages, and get the list of top automobile manufacturers \n",
    "* We can scrape the page to get the additioanal information\n",
    "* We can use this data for further analysis\n",
    "* We can extract the data of two or more different audit month and perform the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [Jovian](https://jovian.ai/) A platform to learn Data Science\n",
    "\n",
    "* This project is made under the guidence of [Aakash N S](https://aakashns.medium.com/) \n",
    "\n",
    "* A Youtube video by `Aakash N S` [Let's Build a Python Web Scraping Project from Scratch | Hands-On Tutorial](https://www.youtube.com/watch?v=RKsLLG-bzEY&t=6677s)\n",
    "\n",
    "* [BeautifulSoup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "                                 \n",
    "* [Pandas Documentation](https://pandas.pydata.org/docs/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
